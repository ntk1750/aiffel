{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iuUEJoF5o2ie",
    "outputId": "1af7a3ca-d13e-4658-8847-5eb006925615"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jRyTvIkrpCTy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path =os.getenv(\"HOME\") +\"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Bvd1038luKjy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") +\"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path =os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8lkTPa4xuSKW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path =  os.getenv(\"HOME\") +\"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "SePPbFP4uUmm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[200])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OVJ_OzUCuWhL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                102464    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 122,051\n",
      "Trainable params: 122,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "# [[YOUR CODE]]\n",
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_dense=64\n",
    "n_train_epoch=25\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "f5Ws53JEuYsi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "10/10 [==============================] - 3s 14ms/step - loss: 31.9266 - accuracy: 0.3233\n",
      "Epoch 2/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.5686 - accuracy: 0.3833\n",
      "Epoch 3/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1864 - accuracy: 0.4800\n",
      "Epoch 4/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9954 - accuracy: 0.5100\n",
      "Epoch 5/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8363 - accuracy: 0.6833\n",
      "Epoch 6/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7680 - accuracy: 0.7133\n",
      "Epoch 7/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6141 - accuracy: 0.7567\n",
      "Epoch 8/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.8267\n",
      "Epoch 9/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.8367\n",
      "Epoch 10/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.8300\n",
      "Epoch 11/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.8467\n",
      "Epoch 12/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3952 - accuracy: 0.8600\n",
      "Epoch 13/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2750 - accuracy: 0.9333\n",
      "Epoch 14/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2452 - accuracy: 0.9300\n",
      "Epoch 15/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2317 - accuracy: 0.9233\n",
      "Epoch 16/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1954 - accuracy: 0.9467\n",
      "Epoch 17/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2144 - accuracy: 0.9333\n",
      "Epoch 18/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1987 - accuracy: 0.9467\n",
      "Epoch 19/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1642 - accuracy: 0.9533\n",
      "Epoch 20/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1141 - accuracy: 0.9733\n",
      "Epoch 21/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0906 - accuracy: 0.9800\n",
      "Epoch 22/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1055 - accuracy: 0.9733\n",
      "Epoch 23/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0742 - accuracy: 0.9933\n",
      "Epoch 24/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0906 - accuracy: 0.9733\n",
      "Epoch 25/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f32ac076130>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test파일 생성 및 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TPBaOIBhuank"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path =os.getenv(\"HOME\") +\"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위  이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"바위  이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "#x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 3)\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "M4CqRs7aucwF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 1.2568 - accuracy: 0.7367\n",
      "test_loss: 1.2568316459655762 \n",
      "test_accuracy: 0.7366666793823242\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "rock_scissor_paper.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
